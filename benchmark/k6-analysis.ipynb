{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = analysis.Analyser(\"k6\")\n",
    "all_data = analyser.get_data()\n",
    "all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_duration_data = all_data[\n",
    "    all_data[\"metric_name\"].isin([\"http_req_duration\", \"grpc_req_duration\"])\n",
    "]\n",
    "req_duration_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop setup data\n",
    "req_duration_data = req_duration_data[req_duration_data[\"group\"] != \"::setup\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = req_duration_data.copy()\n",
    "parts = data[\"name\"].str.split(\"?\", expand=True).rename(columns={0: \"path\", 1: \"query\"})\n",
    "parts[\"path\"] = parts[\"path\"].str.lstrip(\"https://127.0.0.1:8000\")\n",
    "req_duration_data[\"path\"] = parts[\"path\"]\n",
    "if \"query\" in parts:\n",
    "    req_duration_data[\"query\"] = parts[\"query\"]\n",
    "else:\n",
    "    req_duration_data[\"query\"] = [None for _ in range(len(parts[\"path\"]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise endpoints from path\n",
    "req_duration_data[\"endpoint\"] = req_duration_data[\"path\"].map(\n",
    "    lambda x: x.split(\"/\")[-1].lower().replace(\"_\", \"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_vars = [\n",
    "    \"metric_name\",\n",
    "    \"metric_value\",\n",
    "    \"service\",\n",
    "    \"subproto\",\n",
    "    \"proto\",\n",
    "    \"scenario\",\n",
    "    \"status\",\n",
    "    \"tls_version\",\n",
    "    \"url\",\n",
    "    \"name\",\n",
    "    \"extra_tags\",\n",
    "    \"metadata\",\n",
    "    \"check\",\n",
    "    \"error\",\n",
    "    \"error_code\",\n",
    "    \"expected_response\",\n",
    "    \"group\",\n",
    "    \"method\",\n",
    "    \"query\",\n",
    "    \"path\",\n",
    "    \"nodes\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = req_duration_data.copy()\n",
    "if len(data[\"query\"].dropna()) > 0:\n",
    "    var, invariant_vars = analysis.condense_vars(data, ignore_vars + [\"path\"])\n",
    "    data[\"vars\"] = var\n",
    "\n",
    "    txids = data[\"query\"].str.split(\"=\", expand=True)[1]\n",
    "    data[\"txids\"] = txids\n",
    "    txid_counts = data.groupby([\"txids\", \"vars\"]).size()\n",
    "    txid_counts = pd.DataFrame(txid_counts)\n",
    "    txid_counts.rename(columns={0: \"committed_count\"}, inplace=True)\n",
    "\n",
    "    ax = sns.displot(kind=\"ecdf\", data=txid_counts, x=\"committed_count\", hue=\"vars\")\n",
    "    ax.set(title=\"number of commit checks before committed\")\n",
    "    filename = f\"commit_checks_ecdf-committed_count-None-None-vars\"\n",
    "    ax.savefig(os.path.join(analyser.plot_dir(), f\"{filename}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = req_duration_data.copy()\n",
    "if len(data[\"query\"].dropna()) > 0:\n",
    "    var, invariant_vars = analysis.condense_vars(data, ignore_vars + [\"path\"])\n",
    "    data[\"vars\"] = var\n",
    "\n",
    "    grouped = data.groupby([\"path\", \"query\", \"vars\"])\n",
    "\n",
    "    starts = grouped.min(\"start_ms\")\n",
    "    ends = grouped.max(\"end_ms\")\n",
    "\n",
    "    commit_latency_ms = ends[\"end_ms\"] - starts[\"start_ms\"]\n",
    "\n",
    "    latencies = pd.DataFrame(commit_latency_ms)\n",
    "    latencies.rename(columns={0: \"commit_latency\"}, inplace=True)\n",
    "\n",
    "    ax = sns.displot(kind=\"ecdf\", data=latencies, x=\"commit_latency\", hue=\"vars\")\n",
    "    ax.set(title=\"commit latency\")\n",
    "    filename = f\"commit_latency_ecdf-commit_latency-None-None-vars\"\n",
    "    ax.savefig(os.path.join(analyser.plot_dir(), f\"{filename}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data = req_duration_data.copy(deep=False)\n",
    "# plot_data = plot_data[plot_data[\"content_type\"] == \"json\"]\n",
    "# plot_data = plot_data[plot_data[\"rate\"] <= 200]\n",
    "# plot_data = plot_data[plot_data[\"enclave\"] == \"virtual\"]\n",
    "# p = analyser.plot_scatter(plot_data, col=\"http_version\", ignore_vars=ignore_vars)\n",
    "# p.figure.suptitle(\"\")\n",
    "# p.set(xlabel=\"start time (ms)\", ylabel=\"latency (ms)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "p = analyser.plot_ecdf(plot_data, col=\"endpoint\", ignore_vars=ignore_vars)\n",
    "p.figure.suptitle(\"\")\n",
    "p.set(xlabel=\"latency (ms)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "p = analyser.plot_percentile_latency_over_time(\n",
    "    plot_data, col=\"http_version\", ignore_vars=ignore_vars, percentile=0.99\n",
    ")\n",
    "p.figure.suptitle(\"\")\n",
    "p.set(xlabel=\"time (ms)\", ylabel=\"latency (ms)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "p = analyser.plot_throughput_over_time(\n",
    "    plot_data, col=\"http_version\", ignore_vars=ignore_vars + [\"endpoint\"], interval=1000\n",
    ")\n",
    "p.figure.suptitle(\"\")\n",
    "p.set(xlabel=\"time (ms)\", ylabel=\"achieved throughput (req/s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# latency throughput plot func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latency_and_throughput(datasets, labels, ignore_vars):\n",
    "    figure, axis = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "    axis[0].grid(True)\n",
    "    axis[1].grid(True)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        # check that we don't have hidden variables grouped\n",
    "        var, invariant_vars = analysis.condense_vars(dataset, ignore_vars)\n",
    "        assert len(var) == 0, set(var)\n",
    "\n",
    "    print(\"Invariants:\", invariant_vars)\n",
    "\n",
    "    def percentile_latencies(data):\n",
    "        end = data[\"start_s\"].max()\n",
    "        group_cols = [pd.cut(data[\"start_s\"], np.arange(0, end, interval))]\n",
    "        grouped = data.groupby(group_cols)\n",
    "        latencies = grouped.quantile(percentile, numeric_only=True)\n",
    "        mid = latencies.index.map(lambda x: (x.left + x.right) // 2)\n",
    "        latencies[\"mid\"] = mid\n",
    "        x = latencies[\"mid\"]\n",
    "        y = latencies[\"latency_ms\"]\n",
    "        return x, y\n",
    "\n",
    "    def throughput_over_time(data):\n",
    "        x = data[\"start_s\"]\n",
    "        end = data[\"start_s\"].max()\n",
    "        group_cols = [pd.cut(data[\"start_s\"], np.arange(0, end, interval))]\n",
    "        grouped = data.groupby(group_cols)\n",
    "        throughputs = grouped.count() // interval\n",
    "        mid = throughputs.index.map(lambda x: (x.left + x.right) // 2)\n",
    "        throughputs[\"mid\"] = mid\n",
    "        x = throughputs[\"mid\"]\n",
    "        y = throughputs[\"latency_ms\"]\n",
    "        return x, y\n",
    "\n",
    "    interval = 1\n",
    "    percentile = 0.99\n",
    "\n",
    "    for (dataset, label) in zip(datasets, labels):\n",
    "        x, y = percentile_latencies(dataset)\n",
    "\n",
    "        axis[0].plot(x, y, label=label)\n",
    "\n",
    "    axis[0].legend()\n",
    "    axis[0].set_ylabel(\"Request latency (ms)\")\n",
    "\n",
    "    for (dataset, label) in zip(datasets, labels):\n",
    "        x, y = throughput_over_time(dataset)\n",
    "        axis[1].plot(x, y, label=label)\n",
    "\n",
    "    axis[1].legend()\n",
    "\n",
    "    axis[1].set_xlabel(\"Time (s)\")\n",
    "    axis[1].set_ylabel(\"Achieved throughput (req/s)\")\n",
    "\n",
    "    return figure, axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gRPC vs JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "\n",
    "plot_data = plot_data[plot_data[\"http_version\"] == 2]\n",
    "plot_data = plot_data[plot_data[\"enclave\"] == \"sgx\"]\n",
    "plot_data = plot_data[plot_data[\"start_ms\"] > 2000]\n",
    "\n",
    "json_data = plot_data[plot_data[\"content_type\"] == \"json\"]\n",
    "grpc_data = plot_data[plot_data[\"content_type\"] == \"grpc\"]\n",
    "\n",
    "datasets = [json_data, grpc_data]\n",
    "for dataset in datasets:\n",
    "    dataset[\"start_ms\"] -= dataset[\"start_ms\"].min()\n",
    "    dataset[\"start_s\"] = dataset[\"start_ms\"] / 1000\n",
    "\n",
    "plot_latency_and_throughput(\n",
    "    datasets, [\"JSON\", \"gRPC\"], ignore_vars + [\"endpoint\", \"start_s\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTP1 vs HTTP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "\n",
    "plot_data = plot_data[plot_data[\"content_type\"] == \"json\"]\n",
    "plot_data = plot_data[plot_data[\"enclave\"] == \"sgx\"]\n",
    "plot_data = plot_data[plot_data[\"start_ms\"] > 2000]\n",
    "\n",
    "http1_data = plot_data[plot_data[\"http_version\"] == 1]\n",
    "http2_data = plot_data[plot_data[\"http_version\"] == 2]\n",
    "\n",
    "datasets = [http1_data, http2_data]\n",
    "for dataset in datasets:\n",
    "    dataset[\"start_ms\"] -= dataset[\"start_ms\"].min()\n",
    "    dataset[\"start_s\"] = dataset[\"start_ms\"] / 1000\n",
    "\n",
    "plot_latency_and_throughput(\n",
    "    datasets, [\"HTTP1\", \"HTTP2\"], ignore_vars + [\"endpoint\", \"start_s\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overhead of sgx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "\n",
    "plot_data = plot_data[plot_data[\"content_type\"] == \"grpc\"]\n",
    "plot_data = plot_data[plot_data[\"http_version\"] == 2]\n",
    "plot_data = plot_data[plot_data[\"vus\"] == 100]\n",
    "plot_data = plot_data[plot_data[\"start_ms\"] > 2000]\n",
    "\n",
    "sgx_data = plot_data[plot_data[\"enclave\"] == \"sgx\"]\n",
    "virtual_data = plot_data[plot_data[\"enclave\"] == \"virtual\"]\n",
    "\n",
    "datasets = [sgx_data, virtual_data]\n",
    "for dataset in datasets:\n",
    "    dataset[\"start_ms\"] -= dataset[\"start_ms\"].min()\n",
    "    dataset[\"start_s\"] = dataset[\"start_ms\"] / 1000\n",
    "\n",
    "plot_latency_and_throughput(\n",
    "    datasets, [\"SGX\", \"Virtual\"], ignore_vars + [\"endpoint\", \"start_s\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with skipping start to avoid connection setup flurry\n",
    "plot_data = req_duration_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"path\"] != \"app/tx\"]\n",
    "# plot_data = plot_data[plot_data[\"http_version\"] ==2]\n",
    "analyser.plot_achieved_throughput_bar(\n",
    "    plot_data, col=\"content_type\", ignore_vars=ignore_vars\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "# plot_data = plot_data[plot_data[\"http_version\"] == 1]\n",
    "# plot_data = plot_data[plot_data[\"nodes\"] == 1]\n",
    "p = analyser.plot_throughput_bar(plot_data, ignore_vars=ignore_vars + [\"endpoint\"])\n",
    "p.figure.suptitle(\"\")\n",
    "p.set(xlabel=\"target throughput (req/s)\", ylabel=\"achieved throughput ratio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"http_version\"] == 1]\n",
    "plot_data = plot_data[plot_data[\"rate\"] == 4000]\n",
    "plot_data = plot_data[plot_data[\"nodes\"] == 1]\n",
    "var, inv = analysis.condense_vars(plot_data, ignore_vars)\n",
    "plot_data[\"nodes\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"http_version\"] == 1]\n",
    "plot_data = plot_data[plot_data[\"nodes\"].notna()]\n",
    "p = analyser.plot_throughput_bar(plot_data, ignore_vars=ignore_vars + [\"endpoint\"])\n",
    "p.figure.suptitle(\"\")\n",
    "p.set(xlabel=\"target throughput (req/s)\", ylabel=\"achieved throughput ratio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "# plot_data = plot_data[plot_data[\"http_version\"] == 1]\n",
    "p = analyser.plot_throughput_bar(plot_data, ignore_vars=ignore_vars + [\"endpoint\"])\n",
    "p.figure.suptitle(\"\")\n",
    "p.set(xlabel=\"target throughput (req/s)\", ylabel=\"achieved throughput ratio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = req_duration_data.copy(deep=False)\n",
    "p = analyser.plot_target_throughput_latency_line(\n",
    "    plot_data, ignore_vars=ignore_vars + [\"endpoint\"]\n",
    ")\n",
    "p.figure.suptitle(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a93498aa965ac8ed639b230be16e07b1d0996cdf6d66355a89e4f9e95715a96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
