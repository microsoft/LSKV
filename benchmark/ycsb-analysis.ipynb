{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = analysis.Analyser(\"ycsb\")\n",
    "all_data = analyser.get_data()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_vars = [\n",
    "    \"ledger_chunk_bytes\",\n",
    "    \"snapshot_tx_interval\",\n",
    "    \"sig_tx_interval\",\n",
    "    \"sig_ms_interval\",\n",
    "    \"nodes\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All var plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data = all_data.copy(deep=False)\n",
    "# plot_data = plot_data[plot_data[\"start_ms\"] > 250]\n",
    "# analyser.plot_scatter(plot_data, col=\"workload\", ignore_vars=ignore_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"start_ms\"] > 250]\n",
    "analyser.plot_ecdf(plot_data, col=\"workload\", ignore_vars=ignore_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "p = analyser.plot_percentile_latency_over_time(\n",
    "    plot_data, col=\"workload\", ignore_vars=ignore_vars\n",
    ")\n",
    "p.set(xlabel=\"time (ms)\", ylabel=\"latency (ms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "p = analyser.plot_throughput_over_time(\n",
    "    plot_data, col=\"workload\", ignore_vars=ignore_vars\n",
    ")\n",
    "p.set(xlabel=\"time (ms)\", ylabel=\"achieved throughput (req/s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workload comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latency_and_throughput(datasets, labels, col_headers, ignore_vars):\n",
    "    figure, axis = plt.subplots(\n",
    "        2, len(datasets), sharex=\"col\", sharey=\"row\", figsize=(10, 4)\n",
    "    )\n",
    "\n",
    "    for axis_y in axis:\n",
    "        for axis_x in axis_y:\n",
    "            axis_x.grid(True)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        for d in dataset:\n",
    "            # check that we don't have hidden variables grouped\n",
    "            var, invariant_vars = analysis.condense_vars(d, ignore_vars)\n",
    "            assert len(var) == 0, set(var)\n",
    "\n",
    "    print(\"Invariants:\", invariant_vars)\n",
    "\n",
    "    def percentile_latencies(data):\n",
    "        end = data[\"start_s\"].max()\n",
    "        print(end)\n",
    "        group_cols = [pd.cut(data[\"start_s\"], np.arange(0, end, interval))]\n",
    "        grouped = data.groupby(group_cols)\n",
    "        latencies = grouped.quantile(percentile, numeric_only=True)\n",
    "        mid = latencies.index.map(lambda x: (x.left + x.right) // 2)\n",
    "        latencies[\"mid\"] = mid\n",
    "        x = latencies[\"mid\"]\n",
    "        y = latencies[\"latency_ms\"]\n",
    "        return x, y\n",
    "\n",
    "    def throughput_over_time(data):\n",
    "        x = data[\"start_s\"]\n",
    "        end = data[\"start_s\"].max()\n",
    "        group_cols = [pd.cut(data[\"start_s\"], np.arange(0, end, interval))]\n",
    "        grouped = data.groupby(group_cols)\n",
    "        throughputs = grouped.count() // interval\n",
    "        mid = throughputs.index.map(lambda x: (x.left + x.right) // 2)\n",
    "        throughputs[\"mid\"] = mid\n",
    "        x = throughputs[\"mid\"]\n",
    "        y = throughputs[\"latency_ms\"]\n",
    "        return x, y\n",
    "\n",
    "    interval = 1\n",
    "    percentile = 0.99\n",
    "\n",
    "    # set titles on first row\n",
    "    for ax, col in zip(axis[0], col_headers):\n",
    "        ax.set_title(col)\n",
    "\n",
    "    for (dataset, ax) in zip(datasets, axis[0]):\n",
    "        for (d, l) in zip(dataset, labels):\n",
    "            x, y = percentile_latencies(d)\n",
    "\n",
    "            ax.plot(x, y, label=l)\n",
    "\n",
    "        # ax.legend()\n",
    "\n",
    "    axis[0][0].set_ylabel(\"Request latency (ms, 99%)\")\n",
    "\n",
    "    for (dataset, ax) in zip(datasets, axis[1]):\n",
    "        for (d, l) in zip(dataset, labels):\n",
    "            x, y = throughput_over_time(d)\n",
    "            ax.plot(x, y, label=l)\n",
    "\n",
    "    axis[0][-1].legend(bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "    axis[1][2].set_xlabel(\"Time (s)\")\n",
    "    axis[1][0].set_ylabel(\"Achieved throughput (req/s)\")\n",
    "\n",
    "    return figure, axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"threads\"] == 10]\n",
    "\n",
    "etcd_data = plot_data[plot_data[\"store\"] == \"etcd\"]\n",
    "lskv_data = plot_data[plot_data[\"store\"] == \"lskv\"]\n",
    "sgx_data = lskv_data[lskv_data[\"enclave\"] == \"sgx\"]\n",
    "virtual_data = lskv_data[lskv_data[\"enclave\"] == \"virtual\"]\n",
    "\n",
    "etcd_a_data = etcd_data[etcd_data[\"workload\"] == \"workloada\"]\n",
    "etcd_b_data = etcd_data[etcd_data[\"workload\"] == \"workloadb\"]\n",
    "etcd_c_data = etcd_data[etcd_data[\"workload\"] == \"workloadc\"]\n",
    "etcd_d_data = etcd_data[etcd_data[\"workload\"] == \"workloadd\"]\n",
    "etcd_e_data = etcd_data[etcd_data[\"workload\"] == \"workloade\"]\n",
    "etcd_f_data = etcd_data[etcd_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "sgx_a_data = sgx_data[sgx_data[\"workload\"] == \"workloada\"]\n",
    "sgx_b_data = sgx_data[sgx_data[\"workload\"] == \"workloadb\"]\n",
    "sgx_c_data = sgx_data[sgx_data[\"workload\"] == \"workloadc\"]\n",
    "sgx_d_data = sgx_data[sgx_data[\"workload\"] == \"workloadd\"]\n",
    "sgx_e_data = sgx_data[sgx_data[\"workload\"] == \"workloade\"]\n",
    "sgx_f_data = sgx_data[sgx_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "virtual_a_data = virtual_data[virtual_data[\"workload\"] == \"workloada\"]\n",
    "virtual_b_data = virtual_data[virtual_data[\"workload\"] == \"workloadb\"]\n",
    "virtual_c_data = virtual_data[virtual_data[\"workload\"] == \"workloadc\"]\n",
    "virtual_d_data = virtual_data[virtual_data[\"workload\"] == \"workloadd\"]\n",
    "virtual_e_data = virtual_data[virtual_data[\"workload\"] == \"workloade\"]\n",
    "virtual_f_data = virtual_data[virtual_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "datasets = [\n",
    "    [etcd_a_data, sgx_a_data, virtual_a_data],\n",
    "    [etcd_b_data, sgx_b_data, virtual_b_data],\n",
    "    [etcd_c_data, sgx_c_data, virtual_c_data],\n",
    "    [etcd_d_data, sgx_d_data, virtual_d_data],\n",
    "    # [etcd_e_data, sgx_e_data, virtual_e_data],\n",
    "    [etcd_f_data, sgx_f_data, virtual_f_data],\n",
    "]\n",
    "for dataset in datasets:\n",
    "    for d in dataset:\n",
    "        d[\"start_ms\"] -= d[\"start_ms\"].min()\n",
    "        d[\"start_s\"] = d[\"start_ms\"] / 1000\n",
    "\n",
    "fig, axes = plot_latency_and_throughput(\n",
    "    datasets,\n",
    "    [\"etcd\", \"SGX CKVS\", \"Virtual CKVS\"],\n",
    "    [\"Workload A\", \"Workload B\", \"Workload C\", \"Workload D\", \"Workload F\"],\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/anon-workloads-comparison.png\")\n",
    "\n",
    "fig, axes = plot_latency_and_throughput(\n",
    "    datasets,\n",
    "    [\"etcd\", \"SGX LSKV\", \"Virtual LSKV\"],\n",
    "    [\"Workload A\", \"Workload B\", \"Workload C\", \"Workload D\", \"Workload F\"],\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/final-workloads-comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workload e, since it is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latency_cdf_single_workload(datasets, labels, ignore_vars):\n",
    "    figure = plt.figure()\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        # check that we don't have hidden variables grouped\n",
    "        var, invariant_vars = analysis.condense_vars(dataset, ignore_vars)\n",
    "        assert len(var) == 0, set(var)\n",
    "\n",
    "    print(\"Invariants:\", invariant_vars)\n",
    "\n",
    "    for (dataset, label) in zip(datasets, labels):\n",
    "        sns.ecdfplot(data=dataset[\"latency_ms\"], label=label)\n",
    "\n",
    "    figure.legend(bbox_to_anchor=(0.9, 0.5))\n",
    "    plt.xlabel(\"Request latency (ms)\")\n",
    "    plt.ylabel(\"Proportion of requests\")\n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"threads\"] == 10]\n",
    "\n",
    "etcd_data = plot_data[plot_data[\"store\"] == \"etcd\"]\n",
    "lskv_data = plot_data[plot_data[\"store\"] == \"lskv\"]\n",
    "sgx_data = lskv_data[lskv_data[\"enclave\"] == \"sgx\"]\n",
    "virtual_data = lskv_data[lskv_data[\"enclave\"] == \"virtual\"]\n",
    "\n",
    "etcd_e_data = etcd_data[etcd_data[\"workload\"] == \"workloade\"]\n",
    "\n",
    "virtual_e_data = virtual_data[virtual_data[\"workload\"] == \"workloade\"]\n",
    "\n",
    "sgx_e_data = sgx_data[sgx_data[\"workload\"] == \"workloade\"]\n",
    "\n",
    "datasets = [\n",
    "    etcd_e_data,\n",
    "    sgx_e_data,\n",
    "    virtual_e_data,\n",
    "]\n",
    "for dataset in datasets:\n",
    "    dataset[\"start_ms\"] -= dataset[\"start_ms\"].min()\n",
    "    dataset[\"start_s\"] = dataset[\"start_ms\"] / 1000\n",
    "\n",
    "fig = plot_latency_cdf_single_workload(\n",
    "    datasets,\n",
    "    [\"etcd\", \"SGX CKVS\", \"Virtual CKVS\"],\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "# fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/anon-workloade.png\")\n",
    "\n",
    "fig = plot_latency_cdf_single_workload(\n",
    "    datasets,\n",
    "    [\"etcd\", \"SGX LSKV\", \"Virtual LSKV\"],\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.savefig(\"../plots/ycsb/final-workloade.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headline stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headline_stats(workload, enclave, debug=False):\n",
    "    data = all_data.copy(deep=False)\n",
    "\n",
    "    data = data[data[\"workload\"] == workload]\n",
    "\n",
    "    quantile = 0.99\n",
    "\n",
    "    etcd_data = data[data[\"store\"] == \"etcd\"]\n",
    "    var, _ = analysis.condense_vars(etcd_data, ignore_vars + [\"operation\"])\n",
    "    assert len(var) == 0, set(var)\n",
    "\n",
    "    etcd_latency = etcd_data[\"latency_ms\"].quantile(quantile)\n",
    "    etcd_end = etcd_data[\"end_ms\"].max()\n",
    "    etcd_count = etcd_data[\"latency_ms\"].count()\n",
    "    etcd_throughput = etcd_count / (etcd_end / 1000)\n",
    "    if debug:\n",
    "        print(\"etcd latency\", etcd_latency)\n",
    "        print(\"etcd throughput\", etcd_throughput)\n",
    "\n",
    "    lskv_data = data[data[\"store\"] == \"lskv\"]\n",
    "    lskv_data = lskv_data[lskv_data[\"enclave\"] == enclave]\n",
    "    var, _ = analysis.condense_vars(lskv_data, ignore_vars + [\"operation\"])\n",
    "    assert len(var) == 0, set(var)\n",
    "\n",
    "    lskv_latency = lskv_data[\"latency_ms\"].quantile(quantile)\n",
    "    lskv_end = lskv_data[\"end_ms\"].max()\n",
    "    lskv_count = lskv_data[\"latency_ms\"].count()\n",
    "    lskv_throughput = lskv_count / (lskv_end / 1000)\n",
    "    if debug:\n",
    "        print(\"lskv latency\", lskv_latency)\n",
    "        print(\"lskv throughput\", lskv_throughput)\n",
    "\n",
    "    latency_ratio = lskv_latency / etcd_latency\n",
    "    throughput_ratio = lskv_throughput / etcd_throughput\n",
    "    if debug:\n",
    "        print(\"latency improvement\", latency_ratio)\n",
    "        print(\"throughput ratio\", throughput_ratio)\n",
    "\n",
    "    return latency_ratio, throughput_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_latency = 1\n",
    "best_throughput = 1\n",
    "best_workload = \"\"\n",
    "for workload in [\n",
    "    \"workloada\",\n",
    "    \"workloadb\",\n",
    "    \"workloadc\",\n",
    "    \"workloadd\",\n",
    "    \"workloade\",\n",
    "    \"workloadf\",\n",
    "]:\n",
    "    lat, through = headline_stats(workload, \"sgx\")\n",
    "    if lat < best_latency and through > best_throughput:\n",
    "        best_latency = lat\n",
    "        best_throughput = through\n",
    "        best_workload = workload\n",
    "print(\"sgx\", best_latency, best_throughput, best_workload)\n",
    "\n",
    "best_latency = 1\n",
    "best_throughput = 1\n",
    "best_workload = \"\"\n",
    "for workload in [\n",
    "    \"workloada\",\n",
    "    \"workloadb\",\n",
    "    \"workloadc\",\n",
    "    \"workloadd\",\n",
    "    \"workloade\",\n",
    "    \"workloadf\",\n",
    "]:\n",
    "    lat, through = headline_stats(workload, \"virtual\")\n",
    "    if lat < best_latency and through > best_throughput:\n",
    "        best_latency = lat\n",
    "        best_throughput = through\n",
    "        best_workload = workload\n",
    "print(\"virtual\", best_latency, best_throughput, best_workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "analyser.plot_achieved_throughput_bar(\n",
    "    plot_data, ignore_vars=ignore_vars + [\"operation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "analyser.plot_throughput_bar(\n",
    "    plot_data, row=\"nodes\", col=\"operation\", ignore_vars=ignore_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "analyser.plot_target_throughput_latency_line(\n",
    "    plot_data, col=\"nodes\", ignore_vars=ignore_vars\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
