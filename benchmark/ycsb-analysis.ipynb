{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import analysis\n",
    "\n",
    "sns.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyser = analysis.Analyser(\"ycsb\")\n",
    "all_data = analyser.get_data()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ignore_vars = [\n",
    "    \"ledger_chunk_bytes\",\n",
    "    \"snapshot_tx_interval\",\n",
    "    \"sig_tx_interval\",\n",
    "    \"sig_ms_interval\",\n",
    "    \"nodes\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data[all_data[\"operation\"].str.contains(\"ERROR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# All var plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:02:19.888280Z",
     "iopub.status.busy": "2023-01-08T15:02:19.888023Z",
     "iopub.status.idle": "2023-01-08T15:02:19.889951Z",
     "shell.execute_reply": "2023-01-08T15:02:19.889596Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_data = all_data.copy(deep=False)\n",
    "# plot_data = plot_data[plot_data[\"start_ms\"] > 250]\n",
    "# analyser.plot_scatter(plot_data, col=\"workload\", ignore_vars=ignore_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:02:19.891609Z",
     "iopub.status.busy": "2023-01-08T15:02:19.891357Z",
     "iopub.status.idle": "2023-01-08T15:02:53.152019Z",
     "shell.execute_reply": "2023-01-08T15:02:53.151529Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"start_ms\"] > 250]\n",
    "analyser.plot_ecdf(plot_data, col=\"workload\", ignore_vars=ignore_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:02:53.158521Z",
     "iopub.status.busy": "2023-01-08T15:02:53.158123Z",
     "iopub.status.idle": "2023-01-08T15:03:24.422700Z",
     "shell.execute_reply": "2023-01-08T15:03:24.422246Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "p = analyser.plot_percentile_latency_over_time(\n",
    "    plot_data, col=\"workload\", ignore_vars=ignore_vars\n",
    ")\n",
    "p.set(xlabel=\"time (ms)\", ylabel=\"latency (ms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:03:24.429646Z",
     "iopub.status.busy": "2023-01-08T15:03:24.429178Z",
     "iopub.status.idle": "2023-01-08T15:04:13.077255Z",
     "shell.execute_reply": "2023-01-08T15:04:13.076825Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "p = analyser.plot_throughput_over_time(\n",
    "    plot_data, col=\"workload\", ignore_vars=ignore_vars\n",
    ")\n",
    "p.set(xlabel=\"time (ms)\", ylabel=\"achieved throughput (req/s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workload comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_latency_and_throughput(datasets, labels, col_headers, ignore_vars):\n",
    "    figure, axis = plt.subplots(\n",
    "        2, len(datasets), sharex=False, sharey=\"row\", figsize=(10, 4)\n",
    "    )\n",
    "\n",
    "    for axis_y in axis:\n",
    "        for axis_x in axis_y:\n",
    "            axis_x.grid(True)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        for d in dataset:\n",
    "            # check that we don't have hidden variables grouped\n",
    "            var, invariant_vars = analysis.condense_vars(d, ignore_vars + [\"repeat\"])\n",
    "            assert len(var) == 0, set(var)\n",
    "    \n",
    "    print(\"Invariants:\", invariant_vars)\n",
    "\n",
    "    def latencies_cdf(data):\n",
    "        x = np.sort(data)\n",
    "        y = np.cumsum(np.arange(len(x)))\n",
    "        y_max = y[-1]\n",
    "        y = y / y_max\n",
    "        return x, y\n",
    "\n",
    "    def throughput_over_time(data):\n",
    "        x = data[\"start_s\"]\n",
    "        end = data[\"start_s\"].max()\n",
    "        group_cols = [pd.cut(data[\"start_s\"], np.arange(0, end, interval))]\n",
    "        grouped = data.groupby(group_cols)\n",
    "        throughputs = grouped.count() // interval\n",
    "        mid = throughputs.index.map(lambda x: (x.left + x.right) // 2)\n",
    "        throughputs[\"mid\"] = mid\n",
    "        x = throughputs[\"mid\"]\n",
    "        y = throughputs[\"latency_ms\"]\n",
    "        return x, y\n",
    "\n",
    "    interval = 0.1\n",
    "    percentile = 0.99\n",
    "\n",
    "    # set titles on first row\n",
    "    for ax, col in zip(axis[0], col_headers):\n",
    "        ax.set_title(col)\n",
    "\n",
    "    expected_len = 100_000\n",
    "    for dataset, ax in zip(datasets, axis[0]):\n",
    "        for ds, l in zip(dataset, labels):\n",
    "            repeats = set(ds[\"repeat\"])\n",
    "            repeat_latencies = []\n",
    "            for repeat in repeats:\n",
    "                d = ds[ds[\"repeat\"] == repeat]\n",
    "                d = d[:expected_len]\n",
    "                latencies, _ = latencies_cdf(d[\"latency_ms\"])\n",
    "                repeat_latencies.append(latencies)\n",
    "\n",
    "            medians = np.median(repeat_latencies, axis=0)\n",
    "\n",
    "            mins = np.quantile(repeat_latencies, 0.1, axis=0)\n",
    "\n",
    "            maxs = np.quantile(repeat_latencies, 0.9, axis=0)\n",
    "\n",
    "            latencies, proportions = latencies_cdf(medians)\n",
    "            ax.plot(latencies, proportions, label=l)\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "            latencies1, _ = latencies_cdf(mins)\n",
    "            latencies2, _ = latencies_cdf(maxs)\n",
    "\n",
    "            ax.fill_betweenx(proportions, latencies1, latencies2, alpha=0.5, label=l)\n",
    "\n",
    "    axis[0][2].set_xlabel(\"Latency (ms)\")\n",
    "    axis[0][0].set_ylabel(\"Proportion\")\n",
    "\n",
    "    lines = []\n",
    "    for dataset, ax in zip(datasets, axis[1]):\n",
    "        for ds, l in zip(dataset, labels):\n",
    "            repeats = set(ds[\"repeat\"])\n",
    "            repeat_latencies = []\n",
    "            for repeat in repeats:\n",
    "                d = ds[ds[\"repeat\"] == repeat]\n",
    "                d = d[:expected_len]\n",
    "                time, throughput = throughput_over_time(d)\n",
    "                throughput /= 1000.\n",
    "                repeat_latencies.append(throughput)\n",
    "            \n",
    "            min_len = min([len(tp) for tp in repeat_latencies])\n",
    "            repeat_latencies = [tp[:min_len] for tp in repeat_latencies]\n",
    "            time = time[:min_len]\n",
    "\n",
    "            medians = np.median(repeat_latencies, axis=0)\n",
    "\n",
    "            mins = np.quantile(repeat_latencies, 0.1, axis=0)\n",
    "\n",
    "            maxs = np.quantile(repeat_latencies, 0.9, axis=0)\n",
    "\n",
    "            line, = ax.plot(time, medians, label=l)\n",
    "            lines.append(line)\n",
    "\n",
    "            ax.fill_between(time, mins, maxs, alpha=0.5, label=l)\n",
    "\n",
    "    figure.legend(lines, labels, loc=\"lower center\", bbox_to_anchor=(0.73, 0.0), ncols=len(labels))\n",
    "\n",
    "    axis[1][2].set_xlabel(\"Time (s)\")\n",
    "    axis[1][0].set_ylabel(\"Throughput (kreq/s)\")\n",
    "\n",
    "    return figure, axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With etcd on tmpfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"node_count\"] == 3]\n",
    "\n",
    "etcd_data = plot_data[plot_data[\"store\"] == \"etcd\"]\n",
    "etcd_data = etcd_data[etcd_data[\"tmpfs\"] == True]\n",
    "etcd_s_data = etcd_data[etcd_data[\"serializable\"] == True]\n",
    "etcd_l_data = etcd_data[etcd_data[\"serializable\"] == False]\n",
    "lskv_data = plot_data[plot_data[\"store\"] == \"lskv\"]\n",
    "sgx_data = lskv_data[lskv_data[\"enclave\"] == \"sgx\"]\n",
    "virtual_data = lskv_data[lskv_data[\"enclave\"] == \"virtual\"]\n",
    "\n",
    "etcd_s_a_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloada\"]\n",
    "etcd_s_b_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloadb\"]\n",
    "etcd_s_c_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloadc\"]\n",
    "etcd_s_d_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloadd\"]\n",
    "etcd_s_e_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloade\"]\n",
    "etcd_s_f_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "etcd_l_a_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloada\"]\n",
    "etcd_l_b_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloadb\"]\n",
    "etcd_l_c_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloadc\"]\n",
    "etcd_l_d_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloadd\"]\n",
    "etcd_l_e_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloade\"]\n",
    "etcd_l_f_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "sgx_a_data = sgx_data[sgx_data[\"workload\"] == \"workloada\"]\n",
    "sgx_b_data = sgx_data[sgx_data[\"workload\"] == \"workloadb\"]\n",
    "sgx_c_data = sgx_data[sgx_data[\"workload\"] == \"workloadc\"]\n",
    "sgx_d_data = sgx_data[sgx_data[\"workload\"] == \"workloadd\"]\n",
    "sgx_e_data = sgx_data[sgx_data[\"workload\"] == \"workloade\"]\n",
    "sgx_f_data = sgx_data[sgx_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "virtual_a_data = virtual_data[virtual_data[\"workload\"] == \"workloada\"]\n",
    "virtual_b_data = virtual_data[virtual_data[\"workload\"] == \"workloadb\"]\n",
    "virtual_c_data = virtual_data[virtual_data[\"workload\"] == \"workloadc\"]\n",
    "virtual_d_data = virtual_data[virtual_data[\"workload\"] == \"workloadd\"]\n",
    "virtual_e_data = virtual_data[virtual_data[\"workload\"] == \"workloade\"]\n",
    "virtual_f_data = virtual_data[virtual_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "datasets = [\n",
    "    [etcd_s_a_data, etcd_l_a_data, sgx_a_data, virtual_a_data],\n",
    "    [etcd_s_b_data, etcd_l_b_data, sgx_b_data, virtual_b_data],\n",
    "    [etcd_s_c_data, etcd_l_c_data, sgx_c_data, virtual_c_data],\n",
    "    [etcd_s_d_data, etcd_l_d_data, sgx_d_data, virtual_d_data],\n",
    "    [etcd_s_e_data, etcd_l_e_data, sgx_e_data, virtual_e_data],\n",
    "    [etcd_s_f_data, etcd_l_f_data, sgx_f_data, virtual_f_data],\n",
    "]\n",
    "for dataset in datasets:\n",
    "    for d in dataset:\n",
    "        d[\"start_ms\"] -= d[\"start_ms\"].min()\n",
    "        d[\"start_s\"] = d[\"start_ms\"] / 1000\n",
    "\n",
    "col_headers = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "fig, axes = plot_latency_and_throughput(\n",
    "    datasets,\n",
    "    [\"etcd-s\", \"etcd-l\", \"CKVS SGX\", \"CKVS Virtual\"],\n",
    "    col_headers,\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/anon-workloads-comparison-3-tmpfs.pdf\")\n",
    "\n",
    "fig, axes = plot_latency_and_throughput(\n",
    "    datasets,\n",
    "    [\"etcd-s\", \"etcd-l\", \"LSKV SGX\", \"LSKV Virtual\"],\n",
    "    col_headers,\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/final-workloads-comparison-3-tmpfs.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With etcd on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"node_count\"] == 3]\n",
    "\n",
    "etcd_data = plot_data[plot_data[\"store\"] == \"etcd\"]\n",
    "etcd_data = etcd_data[etcd_data[\"tmpfs\"] == False]\n",
    "etcd_s_data = etcd_data[etcd_data[\"serializable\"] == True]\n",
    "etcd_l_data = etcd_data[etcd_data[\"serializable\"] == False]\n",
    "lskv_data = plot_data[plot_data[\"store\"] == \"lskv\"]\n",
    "sgx_data = lskv_data[lskv_data[\"enclave\"] == \"sgx\"]\n",
    "virtual_data = lskv_data[lskv_data[\"enclave\"] == \"virtual\"]\n",
    "\n",
    "etcd_s_a_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloada\"]\n",
    "etcd_s_b_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloadb\"]\n",
    "etcd_s_c_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloadc\"]\n",
    "etcd_s_d_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloadd\"]\n",
    "etcd_s_e_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloade\"]\n",
    "etcd_s_f_data = etcd_s_data[etcd_s_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "etcd_l_a_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloada\"]\n",
    "etcd_l_b_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloadb\"]\n",
    "etcd_l_c_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloadc\"]\n",
    "etcd_l_d_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloadd\"]\n",
    "etcd_l_e_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloade\"]\n",
    "etcd_l_f_data = etcd_l_data[etcd_l_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "sgx_a_data = sgx_data[sgx_data[\"workload\"] == \"workloada\"]\n",
    "sgx_b_data = sgx_data[sgx_data[\"workload\"] == \"workloadb\"]\n",
    "sgx_c_data = sgx_data[sgx_data[\"workload\"] == \"workloadc\"]\n",
    "sgx_d_data = sgx_data[sgx_data[\"workload\"] == \"workloadd\"]\n",
    "sgx_e_data = sgx_data[sgx_data[\"workload\"] == \"workloade\"]\n",
    "sgx_f_data = sgx_data[sgx_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "virtual_a_data = virtual_data[virtual_data[\"workload\"] == \"workloada\"]\n",
    "virtual_b_data = virtual_data[virtual_data[\"workload\"] == \"workloadb\"]\n",
    "virtual_c_data = virtual_data[virtual_data[\"workload\"] == \"workloadc\"]\n",
    "virtual_d_data = virtual_data[virtual_data[\"workload\"] == \"workloadd\"]\n",
    "virtual_e_data = virtual_data[virtual_data[\"workload\"] == \"workloade\"]\n",
    "virtual_f_data = virtual_data[virtual_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "datasets = [\n",
    "    [etcd_s_a_data, etcd_l_a_data, sgx_a_data, virtual_a_data],\n",
    "    [etcd_s_b_data, etcd_l_b_data, sgx_b_data, virtual_b_data],\n",
    "    [etcd_s_c_data, etcd_l_c_data, sgx_c_data, virtual_c_data],\n",
    "    [etcd_s_d_data, etcd_l_d_data, sgx_d_data, virtual_d_data],\n",
    "    [etcd_s_e_data, etcd_l_e_data, sgx_e_data, virtual_e_data],\n",
    "    [etcd_s_f_data, etcd_l_f_data, sgx_f_data, virtual_f_data],\n",
    "]\n",
    "for dataset in datasets:\n",
    "    for d in dataset:\n",
    "        d[\"start_ms\"] -= d[\"start_ms\"].min()\n",
    "        d[\"start_s\"] = d[\"start_ms\"] / 1000\n",
    "\n",
    "col_headers = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "fig, axes = plot_latency_and_throughput(\n",
    "    datasets,\n",
    "    [\"etcd-s\", \"etcd-l\", \"CKVS SGX\", \"CKVS Virtual\"],\n",
    "    col_headers,\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/anon-workloads-comparison-3-disk.pdf\")\n",
    "\n",
    "fig, axes = plot_latency_and_throughput(\n",
    "    datasets,\n",
    "    [\"etcd-s\", \"etcd-l\", \"LSKV SGX\", \"LSKV Virtual\"],\n",
    "    col_headers,\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/final-workloads-comparison-3-disk.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## etcd single node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"threads\"] == 10]\n",
    "plot_data = plot_data[plot_data[\"node_count\"] == 1]\n",
    "\n",
    "etcd_data = plot_data[plot_data[\"store\"] == \"etcd\"]\n",
    "etcd_data = etcd_data[etcd_data[\"enclave\"] == \"virtual\"]\n",
    "lskv_data = plot_data[plot_data[\"store\"] == \"lskv\"]\n",
    "sgx_data = lskv_data[lskv_data[\"enclave\"] == \"sgx\"]\n",
    "virtual_data = lskv_data[lskv_data[\"enclave\"] == \"virtual\"]\n",
    "\n",
    "etcd_a_data = etcd_data[etcd_data[\"workload\"] == \"workloada\"]\n",
    "etcd_b_data = etcd_data[etcd_data[\"workload\"] == \"workloadb\"]\n",
    "etcd_c_data = etcd_data[etcd_data[\"workload\"] == \"workloadc\"]\n",
    "etcd_d_data = etcd_data[etcd_data[\"workload\"] == \"workloadd\"]\n",
    "etcd_e_data = etcd_data[etcd_data[\"workload\"] == \"workloade\"]\n",
    "etcd_f_data = etcd_data[etcd_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "sgx_a_data = sgx_data[sgx_data[\"workload\"] == \"workloada\"]\n",
    "sgx_b_data = sgx_data[sgx_data[\"workload\"] == \"workloadb\"]\n",
    "sgx_c_data = sgx_data[sgx_data[\"workload\"] == \"workloadc\"]\n",
    "sgx_d_data = sgx_data[sgx_data[\"workload\"] == \"workloadd\"]\n",
    "sgx_e_data = sgx_data[sgx_data[\"workload\"] == \"workloade\"]\n",
    "sgx_f_data = sgx_data[sgx_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "virtual_a_data = virtual_data[virtual_data[\"workload\"] == \"workloada\"]\n",
    "virtual_b_data = virtual_data[virtual_data[\"workload\"] == \"workloadb\"]\n",
    "virtual_c_data = virtual_data[virtual_data[\"workload\"] == \"workloadc\"]\n",
    "virtual_d_data = virtual_data[virtual_data[\"workload\"] == \"workloadd\"]\n",
    "virtual_e_data = virtual_data[virtual_data[\"workload\"] == \"workloade\"]\n",
    "virtual_f_data = virtual_data[virtual_data[\"workload\"] == \"workloadf\"]\n",
    "\n",
    "datasets = [\n",
    "    [etcd_a_data, sgx_a_data, virtual_a_data],\n",
    "    [etcd_b_data, sgx_b_data, virtual_b_data],\n",
    "    [etcd_c_data, sgx_c_data, virtual_c_data],\n",
    "    [etcd_d_data, sgx_d_data, virtual_d_data],\n",
    "    [etcd_e_data, sgx_e_data, virtual_e_data],\n",
    "    [etcd_f_data, sgx_f_data, virtual_f_data],\n",
    "]\n",
    "for dataset in datasets:\n",
    "    for d in dataset:\n",
    "        d[\"start_ms\"] -= d[\"start_ms\"].min()\n",
    "        d[\"start_s\"] = d[\"start_ms\"] / 1000\n",
    "\n",
    "col_headers = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "fig, axes = plot_latency_and_throughput(\n",
    "    datasets,\n",
    "    [\"etcd\", \"CKVS SGX\", \"CKVS Virtual\"],\n",
    "    col_headers,\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/anon-workloads-comparison-1.pdf\")\n",
    "\n",
    "fig, axes = plot_latency_and_throughput(\n",
    "    datasets,\n",
    "    [\"etcd\", \"LSKV SGX\", \"LSKV Virtual\"],\n",
    "    col_headers,\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/final-workloads-comparison-1.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workload e, since it is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:04:39.036914Z",
     "iopub.status.busy": "2023-01-08T15:04:39.036470Z",
     "iopub.status.idle": "2023-01-08T15:04:39.040080Z",
     "shell.execute_reply": "2023-01-08T15:04:39.039694Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_latency_cdf_single_workload(datasets, labels, ignore_vars):\n",
    "    figure = plt.figure()\n",
    "\n",
    "    figure.set_figwidth(6.4)\n",
    "    figure.set_figheight(2.4)\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        repeats = set(dataset[\"repeat\"])\n",
    "\n",
    "        # check that we don't have hidden variables grouped\n",
    "        var, invariant_vars = analysis.condense_vars(dataset, ignore_vars + [\"repeat\"])\n",
    "        assert len(var) == 0, set(var)\n",
    "\n",
    "    print(\"Invariants:\", invariant_vars)\n",
    "    \n",
    "    def latencies_cdf(data):\n",
    "        x = np.sort(data)\n",
    "        y = np.cumsum(np.arange(len(x)))\n",
    "        y_max = y[-1]\n",
    "        y = y / y_max\n",
    "        return x, y\n",
    "\n",
    "    expected_len = 1000\n",
    "    \n",
    "    for dataset, label in zip(datasets, labels):\n",
    "        repeats = set(dataset[\"repeat\"])\n",
    "        repeat_latencies = []\n",
    "        for repeat in repeats:\n",
    "            d = dataset[dataset[\"repeat\"] == repeat]\n",
    "            d = d[:expected_len]\n",
    "            latencies, _ = latencies_cdf(d[\"latency_ms\"])\n",
    "            repeat_latencies.append(latencies)\n",
    "            \n",
    "        medians = np.median(repeat_latencies, axis=0)\n",
    "        \n",
    "        mins = np.quantile(repeat_latencies, 0.1, axis=0)\n",
    "        \n",
    "        maxs = np.quantile(repeat_latencies, 0.9, axis=0)\n",
    "\n",
    "        latencies, proportions = latencies_cdf(medians)\n",
    "        plt.plot(latencies, proportions, label=label)\n",
    "        \n",
    "        latencies1, _ = latencies_cdf(mins)\n",
    "        latencies2, _ = latencies_cdf(maxs)\n",
    "\n",
    "        plt.fill_betweenx(proportions, latencies1, latencies2, alpha=0.5)\n",
    "\n",
    "    figure.legend(bbox_to_anchor=(0.95, 0.7))\n",
    "    plt.xlabel(\"Latency (ms)\")\n",
    "    plt.ylabel(\"Proportion of requests\")\n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:04:39.049192Z",
     "iopub.status.busy": "2023-01-08T15:04:39.048878Z",
     "iopub.status.idle": "2023-01-08T15:04:40.835174Z",
     "shell.execute_reply": "2023-01-08T15:04:40.834742Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "plot_data = plot_data[plot_data[\"threads\"] == 10]\n",
    "plot_data = plot_data[plot_data[\"node_count\"] == 1]\n",
    "\n",
    "etcd_data = plot_data[plot_data[\"store\"] == \"etcd\"]\n",
    "etcd_data = etcd_data[etcd_data[\"enclave\"] == \"virtual\"]\n",
    "lskv_data = plot_data[plot_data[\"store\"] == \"lskv\"]\n",
    "sgx_data = lskv_data[lskv_data[\"enclave\"] == \"sgx\"]\n",
    "virtual_data = lskv_data[lskv_data[\"enclave\"] == \"virtual\"]\n",
    "\n",
    "etcd_e_data = etcd_data[etcd_data[\"workload\"] == \"workloade\"]\n",
    "\n",
    "virtual_e_data = virtual_data[virtual_data[\"workload\"] == \"workloade\"]\n",
    "\n",
    "sgx_e_data = sgx_data[sgx_data[\"workload\"] == \"workloade\"]\n",
    "\n",
    "datasets = [\n",
    "    etcd_e_data,\n",
    "    sgx_e_data,\n",
    "    virtual_e_data,\n",
    "]\n",
    "for dataset in datasets:\n",
    "    dataset[\"start_ms\"] -= dataset[\"start_ms\"].min()\n",
    "    dataset[\"start_s\"] = dataset[\"start_ms\"] / 1000\n",
    "\n",
    "fig = plot_latency_cdf_single_workload(\n",
    "    datasets,\n",
    "    [\"etcd\", \"CKVS SGX\", \"CKVS Virtual\"],\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/anon-workloade.pdf\")\n",
    "\n",
    "fig = plot_latency_cdf_single_workload(\n",
    "    datasets,\n",
    "    [\"etcd\", \"LSKV SGX\", \"LSKV Virtual\"],\n",
    "    ignore_vars + [\"start_s\", \"operation\"],\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/ycsb/final-workloade.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headline stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:04:40.837517Z",
     "iopub.status.busy": "2023-01-08T15:04:40.837139Z",
     "iopub.status.idle": "2023-01-08T15:04:40.842473Z",
     "shell.execute_reply": "2023-01-08T15:04:40.842076Z"
    }
   },
   "outputs": [],
   "source": [
    "def headline_stats(workload, enclave, debug=False):\n",
    "    data = all_data.copy(deep=False)\n",
    "\n",
    "    data = data[data[\"workload\"] == workload]\n",
    "    data = data[data[\"node_count\"] == 3]\n",
    "\n",
    "    quantile = 0.99\n",
    "\n",
    "    etcd_data = data[data[\"store\"] == \"etcd\"]\n",
    "    var, _ = analysis.condense_vars(etcd_data, ignore_vars + [\"operation\"])\n",
    "    assert len(var) == 0, set(var)\n",
    "\n",
    "    etcd_latency = etcd_data[\"latency_ms\"].quantile(quantile)\n",
    "    etcd_end = etcd_data[\"end_ms\"].max()\n",
    "    etcd_count = etcd_data[\"latency_ms\"].count()\n",
    "    etcd_throughput = etcd_count / (etcd_end / 1000)\n",
    "    if debug:\n",
    "        print(\"etcd latency\", etcd_latency)\n",
    "        print(\"etcd throughput\", etcd_throughput)\n",
    "\n",
    "    lskv_data = data[data[\"store\"] == \"lskv\"]\n",
    "    lskv_data = lskv_data[lskv_data[\"enclave\"] == enclave]\n",
    "    var, _ = analysis.condense_vars(lskv_data, ignore_vars + [\"operation\"])\n",
    "    assert len(var) == 0, set(var)\n",
    "\n",
    "    lskv_latency = lskv_data[\"latency_ms\"].quantile(quantile)\n",
    "    lskv_end = lskv_data[\"end_ms\"].max()\n",
    "    lskv_count = lskv_data[\"latency_ms\"].count()\n",
    "    lskv_throughput = lskv_count / (lskv_end / 1000)\n",
    "    if debug:\n",
    "        print(\"lskv latency\", lskv_latency)\n",
    "        print(\"lskv throughput\", lskv_throughput)\n",
    "\n",
    "    latency_ratio = lskv_latency / etcd_latency\n",
    "    throughput_ratio = lskv_throughput / etcd_throughput\n",
    "    if debug:\n",
    "        print(\"latency improvement\", latency_ratio)\n",
    "        print(\"throughput ratio\", throughput_ratio)\n",
    "\n",
    "    return latency_ratio, throughput_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:04:40.844230Z",
     "iopub.status.busy": "2023-01-08T15:04:40.843959Z",
     "iopub.status.idle": "2023-01-08T15:04:50.665146Z",
     "shell.execute_reply": "2023-01-08T15:04:50.664678Z"
    }
   },
   "outputs": [],
   "source": [
    "best_latency = 1\n",
    "best_throughput = 1\n",
    "best_workload = \"\"\n",
    "for workload in [\n",
    "    \"workloada\",\n",
    "    \"workloadb\",\n",
    "    \"workloadc\",\n",
    "    \"workloadd\",\n",
    "    \"workloade\",\n",
    "    \"workloadf\",\n",
    "]:\n",
    "    lat, through = headline_stats(workload, \"sgx\")\n",
    "    if lat < best_latency and through > best_throughput:\n",
    "        best_latency = lat\n",
    "        best_throughput = through\n",
    "        best_workload = workload\n",
    "print(\"sgx\", best_latency, best_throughput, best_workload)\n",
    "\n",
    "best_latency = 1\n",
    "best_throughput = 1\n",
    "best_workload = \"\"\n",
    "for workload in [\n",
    "    \"workloada\",\n",
    "    \"workloadb\",\n",
    "    \"workloadc\",\n",
    "    \"workloadd\",\n",
    "    \"workloade\",\n",
    "    \"workloadf\",\n",
    "]:\n",
    "    lat, through = headline_stats(workload, \"virtual\")\n",
    "    if lat < best_latency and through > best_throughput:\n",
    "        best_latency = lat\n",
    "        best_throughput = through\n",
    "        best_workload = workload\n",
    "print(\"virtual\", best_latency, best_throughput, best_workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:04:50.667592Z",
     "iopub.status.busy": "2023-01-08T15:04:50.667146Z",
     "iopub.status.idle": "2023-01-08T15:05:20.221437Z",
     "shell.execute_reply": "2023-01-08T15:05:20.220994Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "analyser.plot_throughput_bar(\n",
    "    plot_data, row=\"nodes\", col=\"operation\", ignore_vars=ignore_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T15:05:20.227404Z",
     "iopub.status.busy": "2023-01-08T15:05:20.226936Z",
     "iopub.status.idle": "2023-01-08T15:06:48.209508Z",
     "shell.execute_reply": "2023-01-08T15:06:48.209062Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = all_data.copy(deep=False)\n",
    "analyser.plot_target_throughput_latency_line(\n",
    "    plot_data, col=\"nodes\", ignore_vars=ignore_vars\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
